{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run init.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Whatever-ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/home/jovyan/project_3/madelon_train_data', \\\n",
    "                         delimiter = ' ', header = None).drop(500, axis = 1)\n",
    "label_data = pd.read_csv('/home/jovyan/project_3/madelon_train_labels', \\\n",
    "                         delimiter = ' ', header = None)[0]\n",
    "validate_data = pd.read_csv('/home/jovyan/project_3/validate_data', \\\n",
    "                         delimiter = ' ', header = None).drop(500, axis =1)\n",
    "validate_labels = pd.read_csv('/home/jovyan/project_3/validate_labels', \\\n",
    "                         delimiter = ' ', header = None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def random_data_sampling():\n",
    "con = pg2.connect(host='34.211.227.227',\n",
    "          dbname='postgres',\n",
    "          user='postgres')\n",
    "cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "sql = 'SELECT feat_257, feat_269, feat_308, feat_315, feat_336, feat_341, feat_395, feat_504, \\\n",
    "feat_526, feat_639, feat_681, feat_701, feat_724, feat_736, feat_769, feat_808, feat_829, \\\n",
    "feat_867, feat_920, feat_956, _id from madelon;'\n",
    "cur.execute(sql)\n",
    "results = cur.fetchall()\n",
    "con.close()\n",
    "df_sample_data = pd.DataFrame(results)\n",
    "df_sample_data.set_index('_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 1 - Benchmarking\n",
    "- build pipeline to perform a naive fit for each of the base model classes:\n",
    "\t- logistic regression\n",
    "\t- decision tree\n",
    "\t- k nearest neighbors\n",
    "\t- support vector classifier\n",
    "- in order to do this, you will need to set a high `C` value in order to perform minimal regularization, in the case of logistic regression and support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_pipe(clf, gs_params = {'clf__C':[0.1, 1]}, data = train_data, target = label_data):\n",
    "    pipe = Pipeline([\n",
    "    ('scaler',MinMaxScaler(feature_range=(0.00001, 1))),\n",
    "    ('clf', clf)\n",
    "    ])\n",
    "    if gs_params == None:\n",
    "        gs = clf\n",
    "    else:\n",
    "        lgls = make_scorer(log_loss)\n",
    "        gs = GridSearchCV(pipe, gs_params, cv=10, scoring=lgls)\n",
    "    gs.fit(data, target)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg = LogisticRegression(C=10000000000000000000000)\n",
    "lgrg_naive = lgrg.fit(train_data, label_data)\n",
    "lgrg_gs = gs_pipe(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc_naive = dtc.fit(train_data, label_data)\n",
    "dtc_params = {\n",
    "    'clf__max_leaf_nodes':[None, 2, 5],\n",
    "}\n",
    "dtc_gs = gs_pipe(dtc, gs_params=dtc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_naive = knn.fit(train_data, label_data)\n",
    "knn_params = {\n",
    "    'clf__leaf_size':[10,20,30],\n",
    "}\n",
    "knn_gs = gs_pipe(knn, gs_params=knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1000000000000000)\n",
    "svc_naive = svc.fit(train_data, label_data)\n",
    "svc_params = {}\n",
    "svc_gs = gs_pipe(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.745, 1.0, 0.82650000000000001, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.score(train_data, label_data) for i in [lgrg_naive, dtc_naive, knn_naive, svc_naive]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58999999999999997, 0.73999999999999999, 0.69166666666666665, 0.5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.score(validate_data, validate_labels) for i in [lgrg_naive, dtc_naive, knn_naive, svc_naive]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.577170862117516,\n",
       " 13.107634356926374,\n",
       " 14.972705893523507,\n",
       " 14.022909532599218]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i.best_score_ for i in [lgrg_gs, dtc_gs, knn_gs, svc_gs]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 2 - Identify Features\n",
    "- Build feature selection pipelines using at least three different techniques\n",
    "- NOTE: these pipelines are being used for feature selection not prediction\n",
    "- Use the results from step 2 to discuss feature importance in the dataset\n",
    "\n",
    "comments:\n",
    "- Probably one pipeline that's Douglas' method.\n",
    "- One pipeline that uses Joshua's method.\n",
    "- One pipeline that passes on the features picked out by a Lasso or something like that.\n",
    "\n",
    "Side note:\n",
    "-What the hell am I going to do to pick out redundant features? Probably just correlation would work - i.e. the most strongly self-related columns are likely highly redundant, after which either using those most predictive of the target variable singularly or finding combinations thereof would be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Significant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def douglas_method(train_data = train_data):\n",
    "    train_data_corr = train_data.corr()\n",
    "    half_corrs = train_data_corr[(train_data_corr[abs(train_data_corr)>0.5]).count() > 1].index\n",
    "    return half_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Josh_method(data = train_data):\n",
    "    score = []; collist = []\n",
    "    for col in data:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            data.drop(col, axis=1), \\\n",
    "            data[col], random_state = 42)\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        score.append(model.score(X_test, y_test))\n",
    "        collist.append(col)\n",
    "    collist = np.array(collist); score = np.array(score)\n",
    "    return collist[score > abs(sum(score)/len(score))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_method(train_data = train_data, label_data = label_data):\n",
    "    selector = SelectKBest(k = 20)\n",
    "    selector.fit_transform(train_data, label_data)\n",
    "    km = train_data.columns[selector.get_support()]\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm = douglas_method(train_data);jm = Josh_method(); km = select_k_method()\n",
    "#km, jm, dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all(jm == dm), all(jm == km)\n",
    "\n",
    "#jmkm_match = [i for i in km if i in jm]; kmdm_match = [i for i in km if i in dm];\n",
    "#jmkm_match == kmdm_match\n",
    "\n",
    "#all(jm == dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 3 - - Testing Model Pipelines\n",
    "Considering these results, develop a strategy for building a final predictive model\n",
    "recommended approaches:\n",
    "- Use feature selection to reduce the dataset to a manageable size then use conventional methods\n",
    "- Use dimension reduction to reduce the dataset to a manageable size then use conventional methods\n",
    "- Use an iterative model training method to use the entire dataset\n",
    "\n",
    "This notebook should be a \"playground\" where you try various approaches to solving this problem\n",
    "\n",
    "So essentially the methods described above are basically just like...\n",
    "- Reduce the # of features you're using so u can do normal shit.\n",
    "- Combine features into new-ish combo ones (i.e. using PCA) so u can do normal shit.\n",
    "- Using repeated random sampling so you can use normal shit despite not actually needing to do so cus such a method is dumb af. Seriously, what the fuck is an iterative model training method??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corr_df(train_data = train_data, method = douglas_method):\n",
    "    half_corrs = method(train_data)\n",
    "    corr_df = train_data[half_corrs].corr()\n",
    "    corr_mask = corr_df[(corr_df > .95) & (corr_df != 1)].notnull()\n",
    "    return corr_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_significant_columns(train_data = train_data, method = make_corr_df):\n",
    "    data = method(train_data)\n",
    "    label_bins = list([col] + list(data.columns[data[col]]) \\\n",
    "                      for col in data.columns)\n",
    "    label_bins = list(set(tuple(sorted(bins)) for bins in label_bins))\n",
    "    return label_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_bins(bins = bin_significant_columns(train_data)):\n",
    "    return [i for j in bins for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_combos_list(label_bins = bin_significant_columns(), num = 5):\n",
    "    return list(combinations([label_bins[i][0] for i in range(len(label_bins))], num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Implementation of Finding Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Brute Force Method:\n",
    "def brute_corr(data = train_data[douglas_method(train_data)], label_data = label_data, \\\n",
    "               model = LinearRegression()):\n",
    "    x = [(i, model.fit(data[list(i)], label_data).score(data[list(i)], label_data))\\\n",
    "            for i in make_combos_list()]\n",
    "    curr = None\n",
    "    for i in x:\n",
    "        if (i[1] > curr) | (curr == None):\n",
    "            curr = i[1]\n",
    "            comb = i[1]\n",
    "    return list(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Method\n",
    "def rf_method(data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    rfclf = RandomForestClassifier()\n",
    "    rfclf.fit_transform(train_data[douglas_method(train_data)], label_data)\n",
    "    return rfclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_method(train_data = train_data, label_data = label_data):\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler(feature_range=(0.00001, 1))),\\\n",
    "              ('sfm', SelectFromModel(RidgeClassifier())),\\\n",
    "              ('kms', KMeans(n_clusters = 32))])\n",
    "    pipe.fit(train_data[douglas_method(train_data)], label_data)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_method(train_data = train_data, label_data = label_data):\n",
    "    sfm = Pipeline([('scaler', MinMaxScaler(feature_range=(0.00001, 1))),\\\n",
    "          ('sfm', SelectFromModel(RidgeClassifier())),\\\n",
    "          ('knn', KNeighborsClassifier())])\n",
    "    sfm.fit(train_data[douglas_method(train_data)], label_data)\n",
    "    return sfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using PCA To Do It?\n",
    "def pca_method(model = KNeighborsClassifier(), data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    pca = IncrementalPCA()\n",
    "    pipe = Pipeline(steps=[('scaler',MinMaxScaler(feature_range=(0.00001, 1))), \\\n",
    "                       ('pca', pca), ('knn', model)])\n",
    "    pipe.fit(data, label_data)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8716666666666667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32.498858803435837"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91666666666666663"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-72.739976624898077"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_method(model =KMeans(n_clusters = 32)).score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Notebook, Step 4 - Build Model\n",
    "\n",
    "Implement your final model\n",
    "(Optionally) use the entire data set\n",
    "\n",
    "\n",
    "I.e. basically just do the shit above in a pipeline????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
