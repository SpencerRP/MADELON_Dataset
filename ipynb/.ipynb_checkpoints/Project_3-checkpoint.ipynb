{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/init.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part One: Extract Data & Create Dataframes\n",
    "\n",
    "##### Original Madelon:\n",
    "These datasets were harvested from the UCI website with curl -o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/home/jovyan/project_3/data/madelon_train_data', \\\n",
    "                         delimiter = ' ', header = None).drop(500, axis = 1)\n",
    "label_data = pd.read_csv('/home/jovyan/project_3/data/madelon_train_labels', \\\n",
    "                         delimiter = ' ', header = None)[0]\n",
    "validate_data = pd.read_csv('/home/jovyan/project_3/data/validate_data', \\\n",
    "                         delimiter = ' ', header = None).drop(500, axis =1)\n",
    "validate_labels = pd.read_csv('/home/jovyan/project_3/data/validate_labels', \\\n",
    "                         delimiter = ' ', header = None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A recreation of Madelon featuring 1000 columns and 200k rows.\n",
    "The database was presampled for .3% of the data, which was then run through Douglas' method for identifying significant features, described in Part Three below. This enabled me to get the complete set of 200k rather than a sample.\n",
    "\n",
    "The original sampling method was performed by finding the _id column_ through a call to the SQL database, and then taking a random sample of ID #'s which were then put into a list and inserted into the resultant query. This method can be found in the random_data_sampling() function in the second cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pg2.connect(host='34.211.227.227',\n",
    "          dbname='postgres',\n",
    "          user='postgres')\n",
    "cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "sql = 'SELECT feat_257, feat_269, feat_308, feat_315, feat_336, feat_341, feat_395, feat_504, \\\n",
    "feat_526, feat_639, feat_681, feat_701, feat_724, feat_736, feat_769, feat_808, feat_829, \\\n",
    "feat_867, feat_920, feat_956, _id from madelon;'\n",
    "cur.execute(sql)\n",
    "results = cur.fetchall()\n",
    "con.close()\n",
    "df_sample_data = pd.DataFrame(results)\n",
    "df_sample_data.set_index('_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_sampling():\n",
    "    con = pg2.connect(host='34.211.227.227',\n",
    "              dbname='postgres',\n",
    "              user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    cur.execute('SELECT _id FROM madelon;')\n",
    "    results = cur.fetchall()\n",
    "    con.close()\n",
    "    df_sample_data = pd.DataFrame(results)\n",
    "\n",
    "    selection = list(df_sample_data.sample(frac=0.005, replace=False)['_id'].values)\n",
    "    selection = [int(i) for i in selection]\n",
    "\n",
    "    con = pg2.connect(host='34.211.227.227',\n",
    "                  dbname='postgres',\n",
    "              user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    sql = 'SELECT * from madelon WHERE _id IN %(selection)s'\n",
    "    cur.execute(sql, {\n",
    "        'selection': tuple(selection),\n",
    "    })\n",
    "    results = cur.fetchall()\n",
    "    con.close()\n",
    "    df_sample_data = pd.DataFrame(results)\n",
    "    df_sample_data.set_index('_id', inplace=True)\n",
    "\n",
    "    return df_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part Two - Benchmarking\n",
    "Each of the following model classes were fit on the complete, unfiltered original Madelon set:\n",
    "- logistic regression\n",
    "- decision tree\n",
    "- k nearest neighbors\n",
    "- support vector classifier\n",
    "These classes were then scored for their performance on both train and test datasets.\n",
    "\n",
    "Note: the same was not performed for the expanded set, but the random_data_sampling function should suffice to provide an unfiltered set of manageable size.\n",
    "\n",
    "##### Pipe & Grid Search Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_pipe(clf, gs_params = {'clf__C':[100000000000000000000000]}, data = train_data, target = label_data):\n",
    "    pipe = Pipeline([\n",
    "    ('scaler',MinMaxScaler(feature_range=(0.00001, 1))),\n",
    "    ('clf', clf)\n",
    "    ])\n",
    "    if gs_params == None:\n",
    "        gs = clf\n",
    "    else:\n",
    "        lgls = make_scorer(log_loss)\n",
    "        gs = GridSearchCV(pipe, gs_params, cv=10, scoring=lgls)\n",
    "    gs.fit(data, target)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Creation & Fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrg = LogisticRegression(C=10000000000000000000000)\n",
    "lgrg_naive = lgrg.fit(train_data, label_data)\n",
    "lgrg_gs = gs_pipe(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc_naive = dtc.fit(train_data, label_data)\n",
    "dtc_params = {\n",
    "    'clf__max_leaf_nodes':[None, 2, 5],\n",
    "}\n",
    "dtc_gs = gs_pipe(dtc, gs_params=dtc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_naive = knn.fit(train_data, label_data)\n",
    "knn_params = {\n",
    "    'clf__leaf_size':[10,20,30],\n",
    "}\n",
    "knn_gs = gs_pipe(knn, gs_params=knn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1000000000000000)\n",
    "svc_naive = svc.fit(train_data, label_data)\n",
    "svc_params = {}\n",
    "svc_gs = gs_pipe(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.745, 1.0, 0.82650000000000001, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.score(train_data, label_data) for i in [lgrg_naive, dtc_naive, knn_naive, svc_naive]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.58999999999999997, 0.73999999999999999, 0.69166666666666665, 0.5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.score(validate_data, validate_labels) for i in [lgrg_naive, dtc_naive, knn_naive, svc_naive]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15.577170862117516,\n",
       " 13.107634356926374,\n",
       " 14.972705893523507,\n",
       " 14.022909532599218]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[i.best_score_ for i in [lgrg_gs, dtc_gs, knn_gs, svc_gs]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part Three - Significant Feature Identification\n",
    "Feature selection methods were built using three different techniques:\n",
    "- Two methods relying upon the known independence of the noisy features in the Madelon dataset, which were generated by a random generated and then scaled to roughly match with the significant features. Both of these methods resulted in the same features.:\n",
    "    - A method developed by a student, Douglas Brodtman (?) that uses a single .corr() matrix to determine which features have some relevance to others. This method is arguably preferable due to the efficient implementation of the well-refined .corr() method.\n",
    "    - A method developed by a teacher, Joshua Cook (?) that attempts to predict a single feature at a time using all other features, with those that have the lowest predictive power being evaluated as noise. This method is arguably inferior due to the lengthy time required to create, fit, and score a model.\n",
    "- A simple SelectFromModel method based upon RidgeClassification. This model returned features different from the above methods, which performed poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def douglas_method(train_data = train_data):\n",
    "    train_data_corr = train_data.corr()\n",
    "    half_corrs = train_data_corr[(train_data_corr[abs(train_data_corr)>0.5]).count() > 1].index\n",
    "    return half_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Josh_method(data = train_data):\n",
    "    score = []; collist = []\n",
    "    for col in data:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "            data.drop(col, axis=1), \\\n",
    "            data[col], random_state = 42)\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        score.append(model.score(X_test, y_test))\n",
    "        collist.append(col)\n",
    "    collist = np.array(collist); score = np.array(score)\n",
    "    return collist[score > abs(sum(score)/len(score))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_method(train_data = train_data, label_data = label_data):\n",
    "    selector = SelectKBest(k = 20)\n",
    "    selector.fit_transform(train_data, label_data)\n",
    "    km = train_data.columns[selector.get_support()]\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dm = douglas_method(train_data);jm = Josh_method(); km = select_k_method()\n",
    "#km, jm, dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all(jm == dm), all(jm == km)\n",
    "\n",
    "#jmkm_match = [i for i in km if i in jm]; kmdm_match = [i for i in km if i in dm];\n",
    "#jmkm_match == kmdm_match\n",
    "\n",
    "#all(jm == dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part Four - Testing Model Pipelines\n",
    "Two main first steps were implemented in order to attempt to find the most relevant - or non-redundant - features out from among the significant features:\n",
    "- Select From model.\n",
    "- Dimension reduction in the form of PCA, and a single implementation was also used to achieve the same effect.\n",
    "- (Implemented but not used:) An expansion upon Douglas' .corr method, using a recognition he made that there were patterns within the significant features as a result of how they were created by making a set of linear combinations and duplicates of the originals and linear combinations - was used to reduce the Madelon dataset to a manageable size. \n",
    "\n",
    "The results of these were then fed into various models:\n",
    "- RandomForest, which did not require any feature selection to perform well.\n",
    "- K Means, which should have found the vertices of the original features but performed horribly.\n",
    "- K Nearest Neighbors, which performed quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expanded Douglas Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions:\n",
    "def make_corr_df(train_data = train_data, method = douglas_method): #creates a second-tier corr\n",
    "    half_corrs = method(train_data)\n",
    "    corr_df = train_data[half_corrs].corr()\n",
    "    corr_mask = corr_df[(corr_df > .95) & (corr_df != 1)].notnull()\n",
    "    return corr_mask\n",
    "\n",
    "def bin_significant_columns(train_data = train_data, method = make_corr_df): \n",
    "    #make bins of patterns.\n",
    "    data = method(train_data)\n",
    "    label_bins = list([col] + list(data.columns[data[col]]) \\\n",
    "                      for col in data.columns)\n",
    "    label_bins = list(set(tuple(sorted(bins)) for bins in label_bins))\n",
    "    return label_bins\n",
    "\n",
    "def flatten_bins(bins = bin_significant_columns(train_data)): \n",
    "    #In order to re-flatten them if necessary\n",
    "    return [i for j in bins for i in j]\n",
    "\n",
    "def make_combos_list(label_bins = bin_significant_columns(), place = 0, num = 5): \n",
    "    #Make a combination from the first in each bin.\n",
    "    #Note: While this method has now been altered to allow for different indexes to be \n",
    "    #selected such was not implemented originally.\n",
    "    return list(combinations([label_bins[binn][int(place/len(binn))] \n",
    "                              for binn in range(len(label_bins))], num))\n",
    "\n",
    "#Brute Force Method for finding out which of the bins provides the most informative features.\n",
    "#Note: It takes a really long time.\n",
    "def brute_corr(data = train_data[douglas_method(train_data)], label_data = label_data, \\\n",
    "               model = LinearRegression()):\n",
    "    x = [(i, model.fit(data[list(i)], label_data).score(data[list(i)], label_data))\\\n",
    "            for i in make_combos_list()]\n",
    "    curr = None\n",
    "    for i in x:\n",
    "        if (i[1] > curr) | (curr == None):\n",
    "            curr = i[1]\n",
    "            comb = i[1]\n",
    "    return list(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of Other Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Method: Performed third best.\n",
    "def rf_method(data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    rfclf = RandomForestClassifier()\n",
    "    rfclf.fit_transform(train_data[douglas_method(train_data)], label_data)\n",
    "    return rfclf\n",
    "\n",
    "#K-Means Method: Performed horribly both with SelectFromModel and with PCA. \n",
    "#I probably could have done something differently.\n",
    "def k_means_method(train_data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler(feature_range=(0.00001, 1))),\\\n",
    "              ('sfm', SelectFromModel(RidgeClassifier())),\\\n",
    "              ('kms', KMeans(n_clusters = 32))])\n",
    "    pipe.fit(train_data[douglas_method(train_data)], label_data)\n",
    "    return pipe\n",
    "\n",
    "#K Nearest Neighbors Method w/ Select From Model: Performed the Best.\n",
    "def knn_method(train_data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    sfm = Pipeline([('scaler', MinMaxScaler(feature_range=(0.00001, 1))),\\\n",
    "          ('sfm', SelectFromModel(RidgeClassifier())),\\\n",
    "          ('knn', KNeighborsClassifier())])\n",
    "    sfm.fit(train_data[douglas_method(train_data)], label_data)\n",
    "    return sfm\n",
    "\n",
    "#K-Nearest Neighbors w/ PCA Method: Perform the Second Best.\n",
    "def pca_method(model = KNeighborsClassifier(), data = train_data[douglas_method(train_data)], label_data = label_data):\n",
    "    pca = IncrementalPCA()\n",
    "    pipe = Pipeline(steps=[('scaler',MinMaxScaler(feature_range=(0.00001, 1))), \\\n",
    "                       ('pca', pca), ('knn', model)])\n",
    "    pipe.fit(data, label_data)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8716666666666667"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-32.498858803435837"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91666666666666663"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_method().score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-72.739976624898077"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_method(model =KMeans(n_clusters = 32)).score(validate_data[douglas_method(validate_data)], validate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "By all appearances, Douglas' method of finding significant features was a good significant feature detector. K Nearest Neighbors fed a SelectFromModel using a RidgeClassifier was the best Pipeline. RandomForest, however, performed quite well without use of SelectFromModel.\n",
    "\n",
    "It is expected that trial-and-error with KMeans and different Classifiers for SelectFromModel to draw features from will result in a pipeline with lower error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
